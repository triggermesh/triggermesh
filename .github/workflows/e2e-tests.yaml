name: End-to-End Testing

on:
  repository_dispatch:
    types: [e2e-test]

jobs:

  e2e-triggermesh:
    name: Test TriggerMesh components
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Report e2e test start
      run: |
        curl \
          -X POST \
          -H "Accept: application/vnd.github+json" \
          -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
          https://api.github.com/repos/triggermesh/triggermesh/statuses/${{ github.event.client_payload.commit_sha }} \
          -d '{"state":"pending","target_url":"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}","context":"${{ github.workflow }}"}'

    - name: Set up Go
      uses: actions/setup-go@v3
      with:
        go-version: '1.19'

    - name: Go caches
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ github.job }}-${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ github.job }}-${{ runner.os }}-go-

    - name: KinD Cluster
      uses: container-tools/kind-action@v2
      with:
        version: v0.13.0
        knative_eventing: v1.4.0
        knative_serving: v1.4.0
        knative_kourier: v1.4.0
        # ko loads images directly into KinD's container runtime when
        # KO_DOCKER_REPO is set to the rogue value "kind.local", so we have no
        # use for a container registry.
        registry: 'false'

    - name: Read KinD network subnet
      id: kind-subnet
      run: |
        kind_subnet_prefix="$(\
          docker network inspect kind -f '{{ (index .IPAM.Config 0).Subnet }}' | cut -d'.' -f'1,2'\
        )"

        echo "Subnet prefix of 'kind' network: ${kind_subnet_prefix}"
        echo "::set-output name=prefix::${kind_subnet_prefix}"

    - name: MetalLB load-balancer
      # Based on https://kind.sigs.k8s.io/docs/user/loadbalancer/
      run: |
        kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.12.1/manifests/namespace.yaml
        kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)"
        kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.12.1/manifests/metallb.yaml
        kubectl -n metallb-system wait --timeout=1m --for=condition=Available deployments.apps/controller

        kubectl create -f - <<'EOM'
        apiVersion: v1
        kind: ConfigMap
        metadata:
          namespace: metallb-system
          name: config
        data:
          config: |
            address-pools:
            - name: default
              protocol: layer2
              addresses:
              - ${{ steps.kind-subnet.outputs.prefix }}.255.200-${{ steps.kind-subnet.outputs.prefix }}.255.250
        EOM

    - name: Knative default domain
      # Sets a magic default Knative domain that resolves to <gateway-ip>.sslip.io
      run: |
        kubectl create -f https://github.com/knative/serving/releases/download/knative-v1.0.0/serving-default-domain.yaml
        kubectl -n knative-serving wait --timeout=1m --for=condition=Complete jobs.batch/default-domain

    - name: Deploy TriggerMesh
      run: |
        sed -i config/500-*.yaml \
          -e "s|ko://github.com/triggermesh/triggermesh/cmd/\(.*$\)|gcr.io/triggermesh/\1:${{ github.event.client_payload.commit_sha }}|g"

        kubectl apply -f config/namespace/
        kubectl apply -f config/

        kubectl -n triggermesh      wait deployments.app --timeout=5m --for=condition=Available -l app.kubernetes.io/part-of=triggermesh
        kubectl -n knative-serving  wait deployments.app --timeout=5m --for=condition=Available -l app.kubernetes.io/name=knative-serving
        kubectl -n knative-eventing wait deployments.app --timeout=5m --for=condition=Available -l app.kubernetes.io/name=knative-eventing

    - name: Install Ginkgo
      run: go install github.com/onsi/ginkgo/v2/ginkgo

    - name: Export KUBECONFIG path
      run: echo "KUBECONFIG=${HOME}/.kube/config" >> $GITHUB_ENV

    # Allows tests to authenticate with Google Cloud using the Google Cloud SDK,
    # e.g. use 'gcloud' as a Git credential helper to interact with Google
    # Cloud Source Repositories.
    - name: Authenticate with Google Cloud
      uses: google-github-actions/auth@v0
      with:
        credentials_json: ${{ secrets.GCLOUD_SERVICEACCOUNT_KEY }}

    - name: Run e2e tests
      id: e2e
      env:
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        GCLOUD_SERVICEACCOUNT_KEY: ${{ secrets.GCLOUD_SERVICEACCOUNT_KEY }}
        AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
        AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
        AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      run: ginkgo -procs=$(($(nproc)*2)) -slow-spec-threshold=10m -randomize-all ./test/e2e/

    - name: Report e2e test result
      if: always()
      run: |
        curl \
          -X POST \
          -H "Accept: application/vnd.github+json" \
          -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
          https://api.github.com/repos/triggermesh/triggermesh/statuses/${{ github.event.client_payload.commit_sha }} \
          -d '{"state":"${{ steps.e2e.outcome == 'success' && 'success' || 'failure' }}","target_url":"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}","context":"${{ github.workflow }}"}'

    # The KinD cluster can get shut down before all API objects created during
    # E2E tests have been terminated, which leaks cloud resources depending on
    # what test(s) are run last by Ginkgo.
    # To prevent that, we delay the completion of the job until all namespaces
    # labeled "e2e-framework" have been finalized.
    - name: Wait for termination of E2E namespaces
      if: always() && steps.e2e.outcome != 'skipped'
      run: |
        declare -i e2e_ns_count=-1

        # allow a grace period of max 300s (150*2s)
        for _ in $(seq 1 150); do
            e2e_ns_count="$(kubectl get ns -l e2e-framework -o jsonpath='{.items}' | jq '. | length')"
            if ! ((e2e_ns_count)); then
                break
            fi

            echo -n '.' >&2
            sleep 2
        done

        # flush stderr
        echo >&2

        # Final retrieval of E2E namespaces, gives us a chance to see whether
        # some of them were still Terminating after the grace period.
        kubectl get ns -l e2e-framework

    - name: Collect logs
      id: logs
      if: failure() && steps.e2e.outcome == 'failure'
      run: |
        tmp_logs="$(mktemp -d)"

        kubectl -n triggermesh logs --tail=-1 -l app=triggermesh-controller > "${tmp_logs}/triggermesh-controller.log"
        kubectl -n triggermesh logs --tail=-1 -l app=triggermesh-webhook    > "${tmp_logs}/triggermesh-webhook.log"

        kubectl -n knative-serving logs --tail=-1 -l app=controller > "${tmp_logs}/serving-controller.log"
        kubectl -n knative-serving logs --tail=-1 -l app=webhook    > "${tmp_logs}/serving-webhook.log"

        kubectl -n knative-eventing logs --tail=-1 -l app=eventing-controller > "${tmp_logs}/eventing-controller.log"
        kubectl -n knative-eventing logs --tail=-1 -l app=eventing-webhook    > "${tmp_logs}/eventing-webhook.log"

        echo "::set-output name=logs_dir::${tmp_logs}"

    - name: Upload logs
      if: failure() && steps.logs.outputs.logs_dir
      uses: actions/upload-artifact@v3
      with:
        name: logs
        path: ${{ steps.logs.outputs.logs_dir }}
